# AC_66

## Business Understanding


### Determine Business Objectives

* **Background:**
     * The project involves analyzing 10 years' worth of data from basketball tournaments, including information about players, teams, coaches, games, and various metrics. The goal is to use this data to predict which teams will qualify for the playoffs in the next season.
     * Analyze data from basketball tournaments, players, teams, coaches, and games over a 10-year period.


* **Business Objectives:**

	* Gain insights from the data analysis.
	* Make data-driven decisions.
	* Optimize the decision-making process related to basketball playoffs qualification.
	* Working accurate machine model that determine which teams will get to the playoffs

*  **Business Success Criteria:**

	The success of the project will be determined by:
	* The accuracy of the predictions made 
	


### Assess Situation

* **Inventory of Resources**
    
    For 10 years, data from players, teams, coaches, games and several other metrics were gathered and arranged on this dataset: This is the dataset that is going to be analyzed in order to make the previsions.
    Software:Python (pandas, numpy, jupyter notebook, google colab, keras)
    

* **Requirements, Assumptions, and Constraints**

 	* **Requirements:**
         - A player needs to have participated in, at least, one game.
 
 	* **Assumptions:**
         - On each season, a coach must guide only one team
 
 	* **Constraints:**
 	     - Time constratint: 24 of november of 2023


* **Risks and Contingencies**
    * Data Quality Issues: There may be missing or inaccurate data in the dataset. Contingency: Data cleaning and imputation strategies will be employed to address missing or erroneous data.

    * Model Accuracy: Predictive models may not perform with high accuracy. Contingency: Iterative model improvement and validation processes will be implemented.

    * Resource Limitations: There may be limitations in computational resources or time constraints. Contingency: Optimization of algorithms and use of cloud computing resources if necessary.

* **Terminology**
    * ????????????????????

* **Costs and Benefits**
    * Cost nothing we don't get payed :)
    * Benefits:
        * Improved accuracy in predicting playoff-qualifying teams.
        * Enhanced decision-making in basketball tournament management.

### Determine Data Mining Goals


* **Data Mining Goals**
    * Create prediction models based on historical basketball tournament data to determine which teams will make the playoffs the next season.
    * Determine the key performance indicators (KPIs) and elements that have a significant impact on a team's playoff qualifying.
    * Find patterns and trends in data from players, teams, and coaches that can be used to maximize playoff qualification methods.
    * Develop a thorough grasp of the correlations between numerous indicators (for example, player statistics, team performance, and coaching techniques) and playoff qualification outcomes.
* **Data Mining Success Criteria**
    * Development of high-accuracy predictive models for anticipating playoff-qualifying teams. 
    * Validation of the models through testing and evaluation to ensure their reliability.

### Project Projet Plan

* **Project Plan**
    * Business Understanding - week 16/09/2023
    * Data Understanding - week 25/09/2023
    * Data Preparation - week 2/10/2023
    * Modeling  - week 9/10/2023 ...
    * Evaluation - ...
    * add more date as we go back and foward?

* **Initial Assessment of Tools and Techniques**
    * Tools and Techniques:
        * Utilize Python for data analysis and modeling, using libraries like pandas, numpy, scikit-learn, and keras.
        * Jupyter Notebook and Google Colab as the primary platforms for coding and analysis.
        * Employ machine learning techniques, including classification algorithms, such as logistic regression, decision trees, random forests, and neural networks, for predictive modeling.
        * Perform feature selection and engineering to improve model accuracy.
        * Implement cross-validation to assess model performance and reduce overfitting.
        * Utilize data visualization tools (e.g., Matplotlib, Seaborn) for exploratory data analysis and model interpretation.

## Data Understanding

## Data Preparation

## Modeling

## Evaluation


