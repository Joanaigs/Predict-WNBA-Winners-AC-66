{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awards_players = pd.read_csv('data/awards_players.csv')\n",
    "df_coaches = pd.read_csv('data/coaches.csv')\n",
    "df_players_teams = pd.read_csv('data/players_teams.csv')\n",
    "df_players = pd.read_csv('data/players.csv')\n",
    "df_series_post = pd.read_csv('data/series_post.csv')\n",
    "df_teams = pd.read_csv('data/teams.csv')\n",
    "df_teams_post = pd.read_csv('data/teams_post.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop collumns that have null values or that have all the same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_columns_with_all_nan(df):\n",
    "    # Step 1: Check for columns with all NaN values\n",
    "    columns_to_drop = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].unique()\n",
    "        if len(unique_values) == 1 or all(pd.isna(x) for x in unique_values):\n",
    "            columns_to_drop.append(col)\n",
    "\n",
    "    # Step 2: Drop identified columns\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Step 3: Print the identified columns to be dropped\n",
    "    print(columns_to_drop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lgID', 'divID', 'seeded', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "['lgIDWinner', 'lgIDLoser']\n",
      "0\n",
      "['firstseason', 'lastseason']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "20\n",
      "['lgID']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "drop_columns_with_all_nan(df_teams)\n",
    "print(df_teams.duplicated().sum())\n",
    "df_teams.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_teams_post)\n",
    "print(df_teams_post.duplicated().sum())\n",
    "df_teams_post.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_series_post)\n",
    "print(df_series_post.duplicated().sum())\n",
    "df_series_post.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_players)\n",
    "print(df_players.duplicated().sum())\n",
    "df_players.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_players_teams)\n",
    "print(df_players_teams.duplicated().sum())\n",
    "df_players_teams.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_coaches)\n",
    "print(df_coaches.duplicated().sum())\n",
    "print(df_coaches.duplicated(subset=['tmID', 'year']).sum())\n",
    "df_coaches.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_awards_players)\n",
    "print(df_awards_players.duplicated().sum())\n",
    "df_awards_players.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregate data according with previous years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have the information about the year at the end of the playoff in each dataset, to avoid data leakage we will aggregate the data from the two previous years to the current year. And create new datasets by doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_back=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are new teams every year we decided to drop all the collumns as only the teams that played before had any relevant information. So as to not have any bias towards the teams that played before, all collumns were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'N' and 'Y' in the 'playoff' column with 0 and 1\n",
    "\n",
    "df_teams['playoff'] = df_teams['playoff'].map({'N': 0, 'Y': 1})\n",
    "df_teams.sort_values(by=['year', 'tmID'], ascending=[True, True], inplace=True)\n",
    "\n",
    "years = df_teams['year'].unique()\n",
    "teams = df_teams['tmID'].unique()\n",
    "\n",
    "df_teams_copy = df_teams.copy()\n",
    "\n",
    "average_collumns = [\"homeW\",\"homeL\",\"awayW\",\"awayL\",\"confW\",\"confL\",\"min\",\"attend\"]\n",
    "\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'num_playoff_appearances'] = df_teams[(df_teams['year'] >= (year - years_back)) & (df_teams['year'] < year) & (df_teams['tmID'] == team)]['playoff'].sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_first_round_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['firstRound'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_first_round_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['firstRound'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_semis_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['semis'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_semis_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['semis'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_finals_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['finals'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_finals_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['finals'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'mean_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['won']).mean()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'mean_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['lost']).mean()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'rank'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['rank']).mean()\n",
    "        for column in average_collumns:\n",
    "            df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), column] = df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)][column].mean()\n",
    " \n",
    "         \n",
    "df_teams_copy.drop(columns=['firstRound', 'semis', 'finals',\"won\",\"lost\", 'franchID', 'name', 'arena', \"o_fgm\",\"o_fga\",\"o_ftm\",\"o_fta\",\"o_3pm\",\"o_3pa\",\"o_oreb\",\"o_dreb\",\"o_reb\",\"o_asts\",\"o_pf\",\"o_stl\",\"o_to\",\"o_blk\",\"o_pts\",\"d_fgm\",\"d_fga\",\"d_ftm\",\"d_fta\",\"d_3pm\",\"d_3pa\",\"d_oreb\",\"d_dreb\",\"d_reb\",\"d_asts\",\"d_pf\",\"d_stl\",\"d_to\",\"d_blk\",\"d_pts\",\"GP\"], inplace=True)\n",
    "df_teams_copy.fillna(0, inplace=True)   \n",
    "df_teams_copy.to_csv('data/teams_processed.csv', index=False)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "categorical_features = ['confID']\n",
    "for feature in categorical_features:\n",
    "    onehotarray = encoder.fit_transform(df_teams_copy[[feature]]).toarray()\n",
    "    items = [f'{feature}_{item}' for item in encoder.categories_[0]]\n",
    "    df_teams_copy[items] = onehotarray\n",
    "df_teams_copy=df_teams_copy.drop(categorical_features, axis=1)\n",
    "\n",
    "df_teams_copy.to_csv('data/teams_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams_post_copy = pd.DataFrame(columns=[\"year\", \"tmID\", \"W\", \"L\"])\n",
    "sum_collumns = [\"W\", \"L\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        for column in sum_collumns:\n",
    "            w=df_teams_post[(df_teams_post['year'] >= (year - years_back)) &(df_teams_post['year'] < year) & (df_teams_post['tmID'] == team)][column].mean()\n",
    "            l=df_teams_post[(df_teams_post['year'] >= (year - years_back)) &(df_teams_post['year'] < year) & (df_teams_post['tmID'] == team)][column].mean()\n",
    "            new_row = {'year':year, 'tmID':team, column:w}\n",
    "            df_teams_post_copy = pd.concat([df_teams_post_copy, pd.DataFrame([new_row])], ignore_index=True)\n",
    "df_teams_post_copy.fillna(0, inplace=True)\n",
    "df_teams_post_copy.to_csv('data/teams_post_processed.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### series post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each team some the number of win and losses they had in the year. For each year we then agregate the information from the previous two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_team_stats = df_series_post.groupby([\"year\", \"tmIDWinner\"])[[\"W\"]].sum().reset_index()\n",
    "winning_team_stats.columns = [\"year\", \"tmID\", \"total_wins\"]\n",
    "\n",
    "losing_team_stats = df_series_post.groupby([\"year\", \"tmIDLoser\"])[[\"L\"]].sum().reset_index()\n",
    "losing_team_stats.columns = [\"year\", \"tmID\", \"total_losses\"]\n",
    "\n",
    "# Merge the winning and losing team statistics\n",
    "team_stats = winning_team_stats.merge(losing_team_stats, on=[\"year\", \"tmID\"], how=\"outer\").fillna(0)\n",
    "team_stats_copy = pd.DataFrame(columns=[\"year\", \"tmID\", \"total_wins\", \"total_losses\"])\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        total_wins = team_stats[(team_stats['year'] >= (year - years_back)) &(team_stats['year'] < year) & (team_stats['tmID'] == team)]['total_wins'].mean()\n",
    "        total_losses = team_stats[(team_stats['year'] >= (year - years_back)) &(team_stats['year'] < year) & (team_stats['tmID'] == team)]['total_losses'].mean()\n",
    "        new_row = {'year': year, 'tmID': team, 'total_wins': total_wins, 'total_losses': total_losses}\n",
    "        team_stats_copy = pd.concat([team_stats_copy, pd.DataFrame([new_row])], ignore_index=True)\n",
    "team_stats_copy.fillna(0, inplace=True)\n",
    "team_stats_copy.to_csv('data/series_post_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_players_teams['Postperformance'] = (df_players_teams['PostPoints'] + df_players_teams['PostRebounds'] +\n",
    "                           df_players_teams['PostAssists'] + df_players_teams['PostSteals'] +\n",
    "                           df_players_teams['PostBlocks']) - (df_players_teams['PostTurnovers'] +\n",
    "                           df_players_teams['PostPF'])   \n",
    "df_players_teams['performance'] = (df_players_teams['points'] + df_players_teams['rebounds'] +\n",
    "                           df_players_teams['assists'] + df_players_teams['steals'] +\n",
    "                           df_players_teams['blocks']) - (df_players_teams['turnovers'] +\n",
    "                           df_players_teams['PF'])   \n",
    "points_made = 1 * df_players_teams['ftMade'] + 2 * (df_players_teams['fgMade'] - df_players_teams['threeMade']) + 3 * df_players_teams['threeMade']\n",
    "points_attempted = 1 * df_players_teams['ftAttempted'] + 2 * (df_players_teams['fgAttempted'] - df_players_teams['threeAttempted']) + 3 * df_players_teams['threeAttempted']\n",
    "df_players_teams['points_precision'] = points_attempted - points_made\n",
    "\n",
    "post_points_made = 1 * df_players_teams['PostftMade'] + 2 * (df_players_teams['PostfgMade'] - df_players_teams['PostthreeMade']) + 3 * df_players_teams['PostthreeMade']\n",
    "post_points_attempted = 1 * df_players_teams['PostftAttempted'] + 2 * (df_players_teams['PostfgAttempted'] - df_players_teams['PostthreeAttempted']) + 3 * df_players_teams['PostthreeAttempted']\n",
    "df_players_teams['Postpoints_precision'] = post_points_attempted - post_points_made\n",
    "\n",
    "df_players_teams.to_csv('dhi', index=False)\n",
    "df_players_teams.drop(columns=['points', 'rebounds', 'assists', 'steals', 'blocks', 'turnovers', 'PF', 'PostPoints', 'PostRebounds', 'PostAssists', 'PostSteals', 'PostBlocks', 'PostTurnovers', 'PostPF'], inplace=True)\n",
    "df_players_teams.drop(columns=['ftMade', 'fgMade', 'threeMade', 'fgAttempted', 'ftAttempted', 'threeAttempted', 'PostftMade', 'PostfgMade', 'PostthreeMade', 'PostfgAttempted', 'PostftAttempted', 'PostthreeAttempted'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each player calculate the statistics of the previous two years, independently of the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jigs2\\Desktop\\AC_66\\data_preparation.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jigs2/Desktop/AC_66/data_preparation.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mfor\u001b[39;00m player \u001b[39min\u001b[39;00m players:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jigs2/Desktop/AC_66/data_preparation.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m average_collumns:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jigs2/Desktop/AC_66/data_preparation.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                 df_players_teams_copy\u001b[39m.\u001b[39mloc[(df_players_teams_copy[\u001b[39m'\u001b[39;49m\u001b[39myear\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m year) \u001b[39m&\u001b[39;49m (df_players_teams_copy[\u001b[39m'\u001b[39;49m\u001b[39mtmID\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m team) \u001b[39m&\u001b[39;49m (df_players_teams_copy[\u001b[39m'\u001b[39;49m\u001b[39mplayerID\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m player), column] \u001b[39m=\u001b[39m df_players_teams[(df_players_teams[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (year \u001b[39m-\u001b[39m years_back)) \u001b[39m&\u001b[39m(df_players_teams[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m year)  \u001b[39m&\u001b[39m (df_players_teams[\u001b[39m'\u001b[39m\u001b[39mplayerID\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m player)][column]\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jigs2/Desktop/AC_66/data_preparation.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df_players_teams_copy\u001b[39m.\u001b[39mdropna(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jigs2/Desktop/AC_66/data_preparation.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m df_players_teams_copy\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mstint\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\arraylike.py:70\u001b[0m, in \u001b[0;36mOpsMixin.__and__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__and__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__and__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_logical_method(other, operator\u001b[39m.\u001b[39;49mand_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:6108\u001b[0m, in \u001b[0;36mSeries._logical_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6105\u001b[0m lvalues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m   6106\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 6108\u001b[0m res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mlogical_op(lvalues, rvalues, op)\n\u001b[0;32m   6109\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\ops\\array_ops.py:396\u001b[0m, in \u001b[0;36mlogical_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    394\u001b[0m     res_values \u001b[39m=\u001b[39m na_logical_op(lvalues, rvalues, op)\n\u001b[0;32m    395\u001b[0m     \u001b[39m# error: Cannot call function of unknown type\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m     res_values \u001b[39m=\u001b[39m filler(res_values)  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\ops\\array_ops.py:363\u001b[0m, in \u001b[0;36mlogical_op.<locals>.fill_bool\u001b[1;34m(x, left)\u001b[0m\n\u001b[0;32m    360\u001b[0m         x[mask] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[39mif\u001b[39;00m left \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m is_bool_dtype(left\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m--> 363\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mastype(\u001b[39mbool\u001b[39;49m)\n\u001b[0;32m    364\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_players_teams_copy = df_players_teams.copy()\n",
    "average_collumns = [\"GP\",\"GS\",\"minutes\",\"oRebounds\",\"dRebounds\",\"dq\",\"PostGP\",\"PostGS\",\"PostMinutes\",\"PostoRebounds\",\"PostdRebounds\",\"PostDQ\", 'performance','Postperformance', 'points_precision', 'Postpoints_precision' ]\n",
    "#average_collumns = [\"GP\",\"GS\",\"minutes\",\"points\",\"oRebounds\",\"dRebounds\",\"rebounds\",\"assists\",\"steals\",\"blocks\",\"turnovers\",\"PF\",\"fgAttempted\",\"fgMade\",\"ftAttempted\",\"ftMade\",\"threeAttempted\",\"threeMade\",\"dq\",\"PostGP\",\"PostGS\",\"PostMinutes\",\"PostPoints\",\"PostoRebounds\",\"PostdRebounds\",\"PostRebounds\",\"PostAssists\",\"PostSteals\",\"PostBlocks\",\"PostTurnovers\",\"PostPF\",\"PostfgAttempted\",\"PostfgMade\",\"PostftAttempted\",\"PostftMade\",\"PostthreeAttempted\",\"PostthreeMade\",\"PostDQ\"]\n",
    "\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        players = df_players_teams[(df_players_teams['year'] == year) & (df_players_teams['tmID'] == team)]['playerID'].unique()\n",
    "        for player in players:\n",
    "            for column in average_collumns:\n",
    "                df_players_teams_copy.loc[(df_players_teams_copy['year'] == year) & (df_players_teams_copy['tmID'] == team) & (df_players_teams_copy['playerID'] == player), column] = df_players_teams[(df_players_teams['year'] >= (year - years_back)) &(df_players_teams['year'] < year)  & (df_players_teams['playerID'] == player)][column].mean()\n",
    "\n",
    "df_players_teams_copy.dropna(inplace=True)\n",
    "df_players_teams_copy.drop(columns=['stint'], inplace=True)\n",
    "df_players_teams_copy.to_csv('data/players_teams_processed.csv', index=False)\n",
    "\n",
    "print(df_players_teams.info(), df_players_teams_copy.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coaches_copy = df_coaches.copy()\n",
    "\n",
    "average_collumns = [\"won\",\"lost\",\"post_wins\",\"post_losses\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        coaches= df_coaches[(df_coaches['year'] == year) & (df_coaches['tmID'] == team)]['coachID'].unique()\n",
    "        for coach in coaches:\n",
    "            for column in average_collumns:\n",
    "                df_coaches_copy.loc[(df_coaches_copy['year'] == year) & (df_coaches_copy['tmID'] == team) & (df_coaches_copy['coachID'] == coach), column] = df_coaches[(df_coaches['year'] >= (year - years_back)) &(df_coaches['year'] < year) & (df_coaches['coachID'] == coach)][column].mean()         \n",
    "\n",
    "df_coaches_copy.fillna(0, inplace=True)\n",
    "df_coaches_copy.to_csv('data/coaches_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeOutliersMean(data, column):\n",
    "    #change the outliers with the mean\n",
    "    #SFinding the IQR\n",
    "    percentile25 = data[column].quantile(0.25)\n",
    "    percentile75 = data[column].quantile(0.75)\n",
    "    #Finding the upper and lower limits\n",
    "    iqr = percentile75 - percentile25\n",
    "    upper_limit = percentile75 + 1.5 * iqr\n",
    "    lower_limit = percentile25 - 1.5 * iqr\n",
    "\n",
    "    # Find outliers\n",
    "    outliers = data[(data[column] > upper_limit) | (data[column] < lower_limit)]\n",
    "\n",
    "    # Replace outliers with the mean of the 'height' column\n",
    "    mean_height = data[column].mean()\n",
    "    data.loc[outliers.index, column] = mean_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop players from whom we have no information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players = df_players[~((df_players['pos'].isna()) &\n",
    "                            (df_players['height'] == 0.0) &\n",
    "                            (df_players['weight'] == 0) &\n",
    "                            (df_players['college'].isna()) &\n",
    "                            (df_players['collegeOther'].isna()) &\n",
    "                            (df_players['birthDate'] == \"0000-00-00\") &\n",
    "                            (df_players['deathDate'] == \"0000-00-00\"))]\n",
    "changeOutliersMean(df_players, 'height')\n",
    "changeOutliersMean(df_players, 'weight')\n",
    "df_players.to_csv('data/players_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awards_players['award_value'] = 1\n",
    "# Assign a weight of 2 to awards related to \"Kim Perrot Sportsmanship\"\n",
    "df_awards_players.loc[df_awards_players['award'].str.contains('Kim Perrot Sportsmanship'), 'award_value'] = 0\n",
    "df_awards_players.loc[df_awards_players['award'].str.contains('Kim Perrot Sportsmanship Award'), 'award_value'] = 0\n",
    "\n",
    "# Assign a weight of 1 to awards related to \"WNBA Finals Most Valuable Player\" and \"All-Star Game Most Valuable Player\"\n",
    "df_awards_players.loc[df_awards_players['award'].isin(['WNBA Finals Most Valuable Player', 'All-Star Game Most Valuable Player', 'Most Valuable Player']), 'award_value'] = 2\n",
    "df_awards_players.to_csv('awards_players_processed.csv', index=False)\n",
    "# Print the updated DataFrame\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "award_counts_copy = pd.DataFrame(columns=[\"year\", \"playerID\", \"award_count\"])\n",
    "players = df_awards_players['playerID'].unique()\n",
    "# Iterate over all possible combinations of \"year\" and \"player\" and add them to the DataFrame\n",
    "for year in years:\n",
    "    for player in players:\n",
    "        award_count = df_awards_players[(df_awards_players['year'] >= (year - years_back)) & (df_awards_players['year'] < year) & (df_awards_players['playerID'] == player)]['award_value'].sum()\n",
    "        new_row = {\"year\": year, \"playerID\": player, \"award_count\": award_count}\n",
    "        award_counts_copy = pd.concat([award_counts_copy, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "award_counts_copy.dropna(inplace=True)\n",
    "award_counts_copy.to_csv('data/awards_players_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
