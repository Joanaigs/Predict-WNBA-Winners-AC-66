{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awards_players = pd.read_csv('data/awards_players.csv')\n",
    "df_coaches = pd.read_csv('data/coaches.csv')\n",
    "df_players_teams = pd.read_csv('data/players_teams.csv')\n",
    "df_players = pd.read_csv('data/players.csv')\n",
    "df_series_post = pd.read_csv('data/series_post.csv')\n",
    "df_teams = pd.read_csv('data/teams.csv')\n",
    "df_teams_post = pd.read_csv('data/teams_post.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop collumns that have null values or that have all the same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_columns_with_all_nan(df):\n",
    "    # Step 1: Check for columns with all NaN values\n",
    "    columns_to_drop = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].unique()\n",
    "        if len(unique_values) == 1 or all(pd.isna(x) for x in unique_values):\n",
    "            columns_to_drop.append(col)\n",
    "\n",
    "    # Step 2: Drop identified columns\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Step 3: Print the identified columns to be dropped\n",
    "    print(columns_to_drop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lgID', 'divID', 'seeded', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "['lgIDWinner', 'lgIDLoser']\n",
      "0\n",
      "['firstseason', 'lastseason']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "20\n",
      "['lgID']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "drop_columns_with_all_nan(df_teams)\n",
    "print(df_teams.duplicated().sum())\n",
    "df_teams.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_teams_post)\n",
    "print(df_teams_post.duplicated().sum())\n",
    "df_teams_post.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_series_post)\n",
    "print(df_series_post.duplicated().sum())\n",
    "df_series_post.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_players)\n",
    "print(df_players.duplicated().sum())\n",
    "df_players.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_players_teams)\n",
    "print(df_players_teams.duplicated().sum())\n",
    "df_players_teams.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_coaches)\n",
    "print(df_coaches.duplicated().sum())\n",
    "print(df_coaches.duplicated(subset=['tmID', 'year']).sum())\n",
    "df_coaches.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_awards_players)\n",
    "print(df_awards_players.duplicated().sum())\n",
    "df_awards_players.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregate data according with previous years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have the information about the year at the end of the playoff in each dataset, to avoid data leakage we will aggregate the data from the two previous years to the current year. And create new datasets by doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_back=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are new teams every year we decided to drop all the collumns as only the teams that played before had any relevant information. So as to not have any bias towards the teams that played before, all collumns were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'N' and 'Y' in the 'playoff' column with 0 and 1\n",
    "df_teams['playoff'] = df_teams['playoff'].map({'N': 0, 'Y': 1})\n",
    "df_teams.sort_values(by=['year', 'tmID'], ascending=[True, True], inplace=True)\n",
    "\n",
    "years = df_teams['year'].unique()\n",
    "teams = df_teams['tmID'].unique()\n",
    "\n",
    "df_teams_copy = df_teams.copy()\n",
    "\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'num_playoff_appearances'] = df_teams[(df_teams['year'] >= (year - years_back)) & (df_teams['year'] < year) & (df_teams['tmID'] == team)]['playoff'].sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_first_round_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['firstRound'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_first_round_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['firstRound'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_semis_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['semis'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_semis_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['semis'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_finals_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['finals'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_finals_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['finals'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'mean_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['won']).mean()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'mean_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['lost']).mean()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'rank'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['rank']).mean()\n",
    "         \n",
    "df_teams_copy.drop(columns=['firstRound', 'semis', 'finals',\"won\",\"lost\", 'franchID', 'name', 'arena', \"o_fgm\",\"o_fga\",\"o_ftm\",\"o_fta\",\"o_3pm\",\"o_3pa\",\"o_oreb\",\"o_dreb\",\"o_reb\",\"o_asts\",\"o_pf\",\"o_stl\",\"o_to\",\"o_blk\",\"o_pts\",\"d_fgm\",\"d_fga\",\"d_ftm\",\"d_fta\",\"d_3pm\",\"d_3pa\",\"d_oreb\",\"d_dreb\",\"d_reb\",\"d_asts\",\"d_pf\",\"d_stl\",\"d_to\",\"d_blk\",\"d_pts\",\"GP\",\"homeW\",\"homeL\",\"awayW\",\"awayL\",\"confW\",\"confL\",\"min\",\"attend\"], inplace=True)\n",
    "df_teams_copy.fillna(0, inplace=True)   \n",
    "df_teams_copy.to_csv('data/teams_processed.csv', index=False)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "categorical_features = ['confID']\n",
    "for feature in categorical_features:\n",
    "    onehotarray = encoder.fit_transform(df_teams_copy[[feature]]).toarray()\n",
    "    items = [f'{feature}_{item}' for item in encoder.categories_[0]]\n",
    "    df_teams_copy[items] = onehotarray\n",
    "df_teams_copy=df_teams_copy.drop(categorical_features, axis=1)\n",
    "\n",
    "df_teams_copy.to_csv('data/teams_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams_post_copy = df_teams_post.copy()\n",
    "sum_collumns = [\"W\", \"L\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        for column in sum_collumns:\n",
    "            df_teams_post_copy.loc[(df_teams_post_copy['year'] == year) & (df_teams_post_copy['tmID'] == team), column] = df_teams_post[(df_teams_post['year'] >= (year - years_back)) &(df_teams_post['year'] < year) & (df_teams_post['tmID'] == team)][column].sum()\n",
    "\n",
    "df_teams_post_copy.fillna(0, inplace=True)\n",
    "df_teams_post_copy.to_csv('data/teams_post_processed.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### series post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each team some the number of win and losses they had in the year. For each year we then agregate the information from the previous two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_team_stats = df_series_post.groupby([\"year\", \"tmIDWinner\"])[[\"W\"]].sum().reset_index()\n",
    "winning_team_stats.columns = [\"year\", \"tmID\", \"total_wins\"]\n",
    "\n",
    "losing_team_stats = df_series_post.groupby([\"year\", \"tmIDLoser\"])[[\"L\"]].sum().reset_index()\n",
    "losing_team_stats.columns = [\"year\", \"tmID\", \"total_losses\"]\n",
    "\n",
    "# Merge the winning and losing team statistics\n",
    "team_stats = winning_team_stats.merge(losing_team_stats, on=[\"year\", \"tmID\"], how=\"outer\").fillna(0)\n",
    "team_stats_copy = team_stats.copy()\n",
    "average_collumns = [\"total_wins\", \"total_losses\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        for column in average_collumns:\n",
    "            team_stats_copy.loc[(team_stats_copy['year'] == year) & (team_stats_copy['tmID'] == team), column] = team_stats[(team_stats['year'] >= (year - years_back)) &(team_stats['year'] < year) & (team_stats['tmID'] == team)][column].mean()\n",
    "team_stats_copy.fillna(0, inplace=True)\n",
    "team_stats_copy.to_csv('data/series_post_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each player calculate the statistics of the previous two years, independently of the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1876 entries, 0 to 1875\n",
      "Data columns (total 42 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   playerID            1876 non-null   object\n",
      " 1   year                1876 non-null   int64 \n",
      " 2   stint               1876 non-null   int64 \n",
      " 3   tmID                1876 non-null   object\n",
      " 4   GP                  1876 non-null   int64 \n",
      " 5   GS                  1876 non-null   int64 \n",
      " 6   minutes             1876 non-null   int64 \n",
      " 7   points              1876 non-null   int64 \n",
      " 8   oRebounds           1876 non-null   int64 \n",
      " 9   dRebounds           1876 non-null   int64 \n",
      " 10  rebounds            1876 non-null   int64 \n",
      " 11  assists             1876 non-null   int64 \n",
      " 12  steals              1876 non-null   int64 \n",
      " 13  blocks              1876 non-null   int64 \n",
      " 14  turnovers           1876 non-null   int64 \n",
      " 15  PF                  1876 non-null   int64 \n",
      " 16  fgAttempted         1876 non-null   int64 \n",
      " 17  fgMade              1876 non-null   int64 \n",
      " 18  ftAttempted         1876 non-null   int64 \n",
      " 19  ftMade              1876 non-null   int64 \n",
      " 20  threeAttempted      1876 non-null   int64 \n",
      " 21  threeMade           1876 non-null   int64 \n",
      " 22  dq                  1876 non-null   int64 \n",
      " 23  PostGP              1876 non-null   int64 \n",
      " 24  PostGS              1876 non-null   int64 \n",
      " 25  PostMinutes         1876 non-null   int64 \n",
      " 26  PostPoints          1876 non-null   int64 \n",
      " 27  PostoRebounds       1876 non-null   int64 \n",
      " 28  PostdRebounds       1876 non-null   int64 \n",
      " 29  PostRebounds        1876 non-null   int64 \n",
      " 30  PostAssists         1876 non-null   int64 \n",
      " 31  PostSteals          1876 non-null   int64 \n",
      " 32  PostBlocks          1876 non-null   int64 \n",
      " 33  PostTurnovers       1876 non-null   int64 \n",
      " 34  PostPF              1876 non-null   int64 \n",
      " 35  PostfgAttempted     1876 non-null   int64 \n",
      " 36  PostfgMade          1876 non-null   int64 \n",
      " 37  PostftAttempted     1876 non-null   int64 \n",
      " 38  PostftMade          1876 non-null   int64 \n",
      " 39  PostthreeAttempted  1876 non-null   int64 \n",
      " 40  PostthreeMade       1876 non-null   int64 \n",
      " 41  PostDQ              1876 non-null   int64 \n",
      "dtypes: int64(40), object(2)\n",
      "memory usage: 615.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1290 entries, 1 to 1871\n",
      "Data columns (total 41 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   playerID            1290 non-null   object \n",
      " 1   year                1290 non-null   int64  \n",
      " 2   tmID                1290 non-null   object \n",
      " 3   GP                  1290 non-null   float64\n",
      " 4   GS                  1290 non-null   float64\n",
      " 5   minutes             1290 non-null   float64\n",
      " 6   points              1290 non-null   float64\n",
      " 7   oRebounds           1290 non-null   float64\n",
      " 8   dRebounds           1290 non-null   float64\n",
      " 9   rebounds            1290 non-null   float64\n",
      " 10  assists             1290 non-null   float64\n",
      " 11  steals              1290 non-null   float64\n",
      " 12  blocks              1290 non-null   float64\n",
      " 13  turnovers           1290 non-null   float64\n",
      " 14  PF                  1290 non-null   float64\n",
      " 15  fgAttempted         1290 non-null   float64\n",
      " 16  fgMade              1290 non-null   float64\n",
      " 17  ftAttempted         1290 non-null   float64\n",
      " 18  ftMade              1290 non-null   float64\n",
      " 19  threeAttempted      1290 non-null   float64\n",
      " 20  threeMade           1290 non-null   float64\n",
      " 21  dq                  1290 non-null   float64\n",
      " 22  PostGP              1290 non-null   float64\n",
      " 23  PostGS              1290 non-null   float64\n",
      " 24  PostMinutes         1290 non-null   float64\n",
      " 25  PostPoints          1290 non-null   float64\n",
      " 26  PostoRebounds       1290 non-null   float64\n",
      " 27  PostdRebounds       1290 non-null   float64\n",
      " 28  PostRebounds        1290 non-null   float64\n",
      " 29  PostAssists         1290 non-null   float64\n",
      " 30  PostSteals          1290 non-null   float64\n",
      " 31  PostBlocks          1290 non-null   float64\n",
      " 32  PostTurnovers       1290 non-null   float64\n",
      " 33  PostPF              1290 non-null   float64\n",
      " 34  PostfgAttempted     1290 non-null   float64\n",
      " 35  PostfgMade          1290 non-null   float64\n",
      " 36  PostftAttempted     1290 non-null   float64\n",
      " 37  PostftMade          1290 non-null   float64\n",
      " 38  PostthreeAttempted  1290 non-null   float64\n",
      " 39  PostthreeMade       1290 non-null   float64\n",
      " 40  PostDQ              1290 non-null   float64\n",
      "dtypes: float64(38), int64(1), object(2)\n",
      "memory usage: 423.3+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "df_players_teams_copy = df_players_teams.copy()\n",
    "\n",
    "average_collumns = [\"GP\",\"GS\",\"minutes\",\"points\",\"oRebounds\",\"dRebounds\",\"rebounds\",\"assists\",\"steals\",\"blocks\",\"turnovers\",\"PF\",\"fgAttempted\",\"fgMade\",\"ftAttempted\",\"ftMade\",\"threeAttempted\",\"threeMade\",\"dq\",\"PostGP\",\"PostGS\",\"PostMinutes\",\"PostPoints\",\"PostoRebounds\",\"PostdRebounds\",\"PostRebounds\",\"PostAssists\",\"PostSteals\",\"PostBlocks\",\"PostTurnovers\",\"PostPF\",\"PostfgAttempted\",\"PostfgMade\",\"PostftAttempted\",\"PostftMade\",\"PostthreeAttempted\",\"PostthreeMade\",\"PostDQ\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        players = df_players_teams[(df_players_teams['year'] == year) & (df_players_teams['tmID'] == team)]['playerID'].unique()\n",
    "        for player in players:\n",
    "            for column in average_collumns:\n",
    "                #df_players_teams_copy.loc[(df_players_teams_copy['year'] == year) & (df_players_teams_copy['tmID'] == team) & (df_players_teams_copy['playerID'] == player), column] = df_players_teams[(df_players_teams['year'] < year) & (df_players_teams['tmID'] == team) & (df_players_teams['playerID'] == player)][column].mean()\n",
    "                df_players_teams_copy.loc[(df_players_teams_copy['year'] == year) & (df_players_teams_copy['tmID'] == team) & (df_players_teams_copy['playerID'] == player), column] = df_players_teams[(df_players_teams['year'] >= (year - years_back)) &(df_players_teams['year'] < year)  & (df_players_teams['playerID'] == player)][column].mean()\n",
    "\n",
    "df_players_teams_copy.dropna(inplace=True)\n",
    "df_players_teams_copy.drop(columns=['stint'], inplace=True)\n",
    "df_players_teams_copy.to_csv('data/players_teams_processed.csv', index=False)\n",
    "\n",
    "print(df_players_teams.info(), df_players_teams_copy.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coaches_copy = df_coaches.copy()\n",
    "\n",
    "average_collumns = [\"won\",\"lost\",\"post_wins\",\"post_losses\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        coaches= df_coaches[(df_coaches['year'] == year) & (df_coaches['tmID'] == team)]['coachID'].unique()\n",
    "        for coach in coaches:\n",
    "            for column in average_collumns:\n",
    "                df_coaches_copy.loc[(df_coaches_copy['year'] == year) & (df_coaches_copy['tmID'] == team) & (df_coaches_copy['coachID'] == coach), column] = df_coaches[(df_coaches['year'] >= (year - years_back)) &(df_coaches['year'] < year) & (df_coaches['coachID'] == coach)][column].mean()         \n",
    "\n",
    "df_coaches_copy.fillna(0, inplace=True)\n",
    "df_coaches_copy.to_csv('data/coaches_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop players from whom we have no information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players = df_players[~((df_players['pos'].isna()) &\n",
    "                            (df_players['height'] == 0.0) &\n",
    "                            (df_players['weight'] == 0) &\n",
    "                            (df_players['college'].isna()) &\n",
    "                            (df_players['collegeOther'].isna()) &\n",
    "                            (df_players['birthDate'] == \"0000-00-00\") &\n",
    "                            (df_players['deathDate'] == \"0000-00-00\"))]\n",
    "df_players.to_csv('data/players_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_counts = df_awards_players.groupby([\"year\", \"playerID\"]).size().reset_index(name=\"award_count\")\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "award_counts_copy = pd.DataFrame(columns=[\"year\", \"playerID\", \"award_count\"])\n",
    "players = df_awards_players['playerID'].unique()\n",
    "# Iterate over all possible combinations of \"year\" and \"player\" and add them to the DataFrame\n",
    "for year in years:\n",
    "    for player in players:\n",
    "        award_count = award_counts[(award_counts['year'] >= (year - years_back)) & (award_counts['year'] < year) & (award_counts['playerID'] == player)]['award_count'].sum()\n",
    "        new_row = {\"year\": year, \"playerID\": player, \"award_count\": award_count}\n",
    "        award_counts_copy = pd.concat([award_counts_copy, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "award_counts_copy.dropna(inplace=True)\n",
    "award_counts_copy.to_csv('data/awards_players_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
