{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awards_players = pd.read_csv('data/awards_players.csv')\n",
    "df_coaches = pd.read_csv('data/coaches.csv')\n",
    "df_players_teams = pd.read_csv('data/players_teams.csv')\n",
    "df_players = pd.read_csv('data/players.csv')\n",
    "df_series_post = pd.read_csv('data/series_post.csv')\n",
    "df_teams = pd.read_csv('data/teams.csv')\n",
    "df_teams_post = pd.read_csv('data/teams_post.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_back=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_columns_with_all_nan(df):\n",
    "    # Step 1: Check for columns with all NaN values\n",
    "    columns_to_drop = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].unique()\n",
    "        if len(unique_values) == 1 or all(pd.isna(x) for x in unique_values):\n",
    "            columns_to_drop.append(col)\n",
    "\n",
    "    # Step 2: Drop identified columns\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Step 3: Print the identified columns to be dropped\n",
    "    print(columns_to_drop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lgID', 'divID', 'seeded', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "['lgIDWinner', 'lgIDLoser']\n",
      "0\n",
      "['firstseason', 'lastseason']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "20\n",
      "['lgID']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "drop_columns_with_all_nan(df_teams)\n",
    "print(df_teams.duplicated().sum())\n",
    "df_teams.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_teams_post)\n",
    "print(df_teams_post.duplicated().sum())\n",
    "df_teams_post.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_series_post)\n",
    "print(df_series_post.duplicated().sum())\n",
    "df_series_post.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_players)\n",
    "print(df_players.duplicated().sum())\n",
    "df_players.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_players_teams)\n",
    "print(df_players_teams.duplicated().sum())\n",
    "df_players_teams.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_coaches)\n",
    "print(df_coaches.duplicated().sum())\n",
    "print(df_coaches.duplicated(subset=['tmID', 'year']).sum())\n",
    "df_coaches.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_awards_players)\n",
    "print(df_awards_players.duplicated().sum())\n",
    "df_awards_players.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'N' and 'Y' in the 'playoff' column with 0 and 1\n",
    "df_teams['playoff'] = df_teams['playoff'].map({'N': 0, 'Y': 1})\n",
    "df_teams.sort_values(by=['year', 'tmID'], ascending=[True, True], inplace=True)\n",
    "\n",
    "years = df_teams['year'].unique()\n",
    "teams = df_teams['tmID'].unique()\n",
    "\n",
    "df_teams_copy = df_teams.copy()\n",
    "\n",
    "\n",
    "average_collumns = [\"o_fgm\",\"o_fga\",\"o_ftm\",\"o_fta\",\"o_3pm\",\"o_3pa\",\"o_oreb\",\"o_dreb\",\"o_reb\",\"o_asts\",\"o_pf\",\"o_stl\",\"o_to\",\"o_blk\",\"o_pts\",\"d_fgm\",\"d_fga\",\"d_ftm\",\"d_fta\",\"d_3pm\",\"d_3pa\",\"d_oreb\",\"d_dreb\",\"d_reb\",\"d_asts\",\"d_pf\",\"d_stl\",\"d_to\",\"d_blk\",\"d_pts\",\"GP\",\"homeW\",\"homeL\",\"awayW\",\"awayL\",\"confW\",\"confL\",\"min\",\"attend\"]\n",
    "\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'num_playoff_appearances'] = df_teams[(df_teams['year'] >= (year - years_back)) & (df_teams['year'] < year) & (df_teams['tmID'] == team)]['playoff'].sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_first_round_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['firstRound'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_first_round_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['firstRound'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_semis_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['semis'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_semis_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['semis'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_finals_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['finals'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_finals_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['finals'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'mean_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['won']).mean()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'mean_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['lost']).mean()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'rank'] = (df_teams[(df_teams['year'] < year) & (df_teams['tmID'] == team)]['playoff']).mean()\n",
    "        for column in average_collumns:\n",
    "            df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), column] = df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)][column].mean()\n",
    "            \n",
    "df_teams_copy.drop(columns=['firstRound', 'semis', 'finals',\"won\",\"lost\", 'franchID', 'name', 'arena'], inplace=True)\n",
    "df_teams_copy.fillna(0, inplace=True)   \n",
    "df_teams_copy.to_csv('data/teams_processed.csv', index=False)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "categorical_features = ['confID']\n",
    "for feature in categorical_features:\n",
    "    onehotarray = encoder.fit_transform(df_teams_copy[[feature]]).toarray()\n",
    "    items = [f'{feature}_{item}' for item in encoder.categories_[0]]\n",
    "    df_teams_copy[items] = onehotarray\n",
    "df_teams_copy=df_teams_copy.drop(categorical_features, axis=1)\n",
    "\n",
    "df_teams_copy.to_csv('data/teams_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams_post_copy = df_teams_post.copy()\n",
    "sum_collumns = [\"W\", \"L\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        for column in sum_collumns:\n",
    "            df_teams_post_copy.loc[(df_teams_post_copy['year'] == year) & (df_teams_post_copy['tmID'] == team), column] = df_teams_post[(df_teams_post['year'] >= (year - years_back)) &(df_teams_post['year'] < year) & (df_teams_post['tmID'] == team)][column].sum()\n",
    "\n",
    "df_teams_post_copy.fillna(0, inplace=True)\n",
    "df_teams_post_copy.to_csv('data/teams_post_processed.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### series post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_team_stats = df_series_post.groupby([\"year\", \"tmIDWinner\"])[[\"W\"]].sum().reset_index()\n",
    "winning_team_stats.columns = [\"year\", \"tmID\", \"total_wins\"]\n",
    "\n",
    "losing_team_stats = df_series_post.groupby([\"year\", \"tmIDLoser\"])[[\"L\"]].sum().reset_index()\n",
    "losing_team_stats.columns = [\"year\", \"tmID\", \"total_losses\"]\n",
    "\n",
    "# Merge the winning and losing team statistics\n",
    "team_stats = winning_team_stats.merge(losing_team_stats, on=[\"year\", \"tmID\"], how=\"outer\").fillna(0)\n",
    "team_stats_copy = team_stats.copy()\n",
    "average_collumns = [\"total_wins\", \"total_losses\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        for column in average_collumns:\n",
    "            team_stats_copy.loc[(team_stats_copy['year'] == year) & (team_stats_copy['tmID'] == team), column] = team_stats[(team_stats['year'] >= (year - years_back)) &(team_stats['year'] < year) & (team_stats['tmID'] == team)][column].mean()\n",
    "team_stats_copy.fillna(0, inplace=True)\n",
    "team_stats_copy.to_csv('data/series_post_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1876 entries, 0 to 1875\n",
      "Data columns (total 42 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   playerID            1876 non-null   object\n",
      " 1   year                1876 non-null   int64 \n",
      " 2   stint               1876 non-null   int64 \n",
      " 3   tmID                1876 non-null   object\n",
      " 4   GP                  1876 non-null   int64 \n",
      " 5   GS                  1876 non-null   int64 \n",
      " 6   minutes             1876 non-null   int64 \n",
      " 7   points              1876 non-null   int64 \n",
      " 8   oRebounds           1876 non-null   int64 \n",
      " 9   dRebounds           1876 non-null   int64 \n",
      " 10  rebounds            1876 non-null   int64 \n",
      " 11  assists             1876 non-null   int64 \n",
      " 12  steals              1876 non-null   int64 \n",
      " 13  blocks              1876 non-null   int64 \n",
      " 14  turnovers           1876 non-null   int64 \n",
      " 15  PF                  1876 non-null   int64 \n",
      " 16  fgAttempted         1876 non-null   int64 \n",
      " 17  fgMade              1876 non-null   int64 \n",
      " 18  ftAttempted         1876 non-null   int64 \n",
      " 19  ftMade              1876 non-null   int64 \n",
      " 20  threeAttempted      1876 non-null   int64 \n",
      " 21  threeMade           1876 non-null   int64 \n",
      " 22  dq                  1876 non-null   int64 \n",
      " 23  PostGP              1876 non-null   int64 \n",
      " 24  PostGS              1876 non-null   int64 \n",
      " 25  PostMinutes         1876 non-null   int64 \n",
      " 26  PostPoints          1876 non-null   int64 \n",
      " 27  PostoRebounds       1876 non-null   int64 \n",
      " 28  PostdRebounds       1876 non-null   int64 \n",
      " 29  PostRebounds        1876 non-null   int64 \n",
      " 30  PostAssists         1876 non-null   int64 \n",
      " 31  PostSteals          1876 non-null   int64 \n",
      " 32  PostBlocks          1876 non-null   int64 \n",
      " 33  PostTurnovers       1876 non-null   int64 \n",
      " 34  PostPF              1876 non-null   int64 \n",
      " 35  PostfgAttempted     1876 non-null   int64 \n",
      " 36  PostfgMade          1876 non-null   int64 \n",
      " 37  PostftAttempted     1876 non-null   int64 \n",
      " 38  PostftMade          1876 non-null   int64 \n",
      " 39  PostthreeAttempted  1876 non-null   int64 \n",
      " 40  PostthreeMade       1876 non-null   int64 \n",
      " 41  PostDQ              1876 non-null   int64 \n",
      "dtypes: int64(40), object(2)\n",
      "memory usage: 615.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1876 entries, 0 to 1875\n",
      "Data columns (total 41 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   playerID            1876 non-null   object \n",
      " 1   year                1876 non-null   int64  \n",
      " 2   tmID                1876 non-null   object \n",
      " 3   GP                  1876 non-null   float64\n",
      " 4   GS                  1876 non-null   float64\n",
      " 5   minutes             1876 non-null   float64\n",
      " 6   points              1876 non-null   float64\n",
      " 7   oRebounds           1876 non-null   float64\n",
      " 8   dRebounds           1876 non-null   float64\n",
      " 9   rebounds            1876 non-null   float64\n",
      " 10  assists             1876 non-null   float64\n",
      " 11  steals              1876 non-null   float64\n",
      " 12  blocks              1876 non-null   float64\n",
      " 13  turnovers           1876 non-null   float64\n",
      " 14  PF                  1876 non-null   float64\n",
      " 15  fgAttempted         1876 non-null   float64\n",
      " 16  fgMade              1876 non-null   float64\n",
      " 17  ftAttempted         1876 non-null   float64\n",
      " 18  ftMade              1876 non-null   float64\n",
      " 19  threeAttempted      1876 non-null   float64\n",
      " 20  threeMade           1876 non-null   float64\n",
      " 21  dq                  1876 non-null   float64\n",
      " 22  PostGP              1876 non-null   float64\n",
      " 23  PostGS              1876 non-null   float64\n",
      " 24  PostMinutes         1876 non-null   float64\n",
      " 25  PostPoints          1876 non-null   float64\n",
      " 26  PostoRebounds       1876 non-null   float64\n",
      " 27  PostdRebounds       1876 non-null   float64\n",
      " 28  PostRebounds        1876 non-null   float64\n",
      " 29  PostAssists         1876 non-null   float64\n",
      " 30  PostSteals          1876 non-null   float64\n",
      " 31  PostBlocks          1876 non-null   float64\n",
      " 32  PostTurnovers       1876 non-null   float64\n",
      " 33  PostPF              1876 non-null   float64\n",
      " 34  PostfgAttempted     1876 non-null   float64\n",
      " 35  PostfgMade          1876 non-null   float64\n",
      " 36  PostftAttempted     1876 non-null   float64\n",
      " 37  PostftMade          1876 non-null   float64\n",
      " 38  PostthreeAttempted  1876 non-null   float64\n",
      " 39  PostthreeMade       1876 non-null   float64\n",
      " 40  PostDQ              1876 non-null   float64\n",
      "dtypes: float64(38), int64(1), object(2)\n",
      "memory usage: 601.0+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "df_players_teams_copy = df_players_teams.copy()\n",
    "\n",
    "average_collumns = [\"GP\",\"GS\",\"minutes\",\"points\",\"oRebounds\",\"dRebounds\",\"rebounds\",\"assists\",\"steals\",\"blocks\",\"turnovers\",\"PF\",\"fgAttempted\",\"fgMade\",\"ftAttempted\",\"ftMade\",\"threeAttempted\",\"threeMade\",\"dq\",\"PostGP\",\"PostGS\",\"PostMinutes\",\"PostPoints\",\"PostoRebounds\",\"PostdRebounds\",\"PostRebounds\",\"PostAssists\",\"PostSteals\",\"PostBlocks\",\"PostTurnovers\",\"PostPF\",\"PostfgAttempted\",\"PostfgMade\",\"PostftAttempted\",\"PostftMade\",\"PostthreeAttempted\",\"PostthreeMade\",\"PostDQ\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        players = df_players_teams[(df_players_teams['year'] == year) & (df_players_teams['tmID'] == team)]['playerID'].unique()\n",
    "        for player in players:\n",
    "            for column in average_collumns:\n",
    "                #df_players_teams_copy.loc[(df_players_teams_copy['year'] == year) & (df_players_teams_copy['tmID'] == team) & (df_players_teams_copy['playerID'] == player), column] = df_players_teams[(df_players_teams['year'] < year) & (df_players_teams['tmID'] == team) & (df_players_teams['playerID'] == player)][column].mean()\n",
    "                df_players_teams_copy.loc[(df_players_teams_copy['year'] == year) & (df_players_teams_copy['tmID'] == team) & (df_players_teams_copy['playerID'] == player), column] = df_players_teams[(df_players_teams['year'] >= (year - years_back)) &(df_players_teams['year'] < year)  & (df_players_teams['playerID'] == player)][column].mean()\n",
    "\n",
    "df_players_teams_copy.fillna(0, inplace=True)\n",
    "df_players_teams_copy.drop(columns=['stint'], inplace=True)\n",
    "df_players_teams_copy.to_csv('data/players_teams_processed.csv', index=False)\n",
    "\n",
    "print(df_players_teams.info(), df_players_teams_copy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coaches_copy = df_coaches.copy()\n",
    "\n",
    "average_collumns = [\"won\",\"lost\",\"post_wins\",\"post_losses\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        coaches= df_coaches[(df_coaches['year'] == year) & (df_coaches['tmID'] == team)]['coachID'].unique()\n",
    "        for coach in coaches:\n",
    "            for column in average_collumns:\n",
    "                #df_coaches_copy.loc[(df_coaches_copy['year'] == year) & (df_coaches_copy['tmID'] == team), column] = agg_coaches_df[(agg_coaches_df['year'] < year) & (agg_coaches_df['tmID'] == team)][column].mean()\n",
    "                df_coaches_copy.loc[(df_coaches_copy['year'] == year) & (df_coaches_copy['tmID'] == team) & (df_coaches_copy['coachID'] == coach), column] = df_coaches[(df_coaches['year'] >= (year - years_back)) &(df_coaches['year'] < year) & (df_coaches['coachID'] == coach)][column].mean()\n",
    "\n",
    "agg_coaches_df = df_coaches_copy.groupby([\"year\", \"tmID\"]).agg({\n",
    "    \"won\": \"sum\",\n",
    "    \"lost\": \"sum\",\n",
    "    \"post_wins\": \"sum\",\n",
    "    \"post_losses\": \"sum\",\n",
    "}).reset_index()\n",
    "agg_coaches_df.fillna(0, inplace=True)\n",
    "agg_coaches_df.to_csv('data/coaches_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioID</th>\n",
       "      <th>pos</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>college</th>\n",
       "      <th>collegeOther</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>deathDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrahta01w</td>\n",
       "      <td>C</td>\n",
       "      <td>74.0</td>\n",
       "      <td>190</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-09-27</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>F</td>\n",
       "      <td>74.0</td>\n",
       "      <td>169</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-07-09</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adairje01w</td>\n",
       "      <td>C</td>\n",
       "      <td>76.0</td>\n",
       "      <td>197</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986-12-19</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adamsda01w</td>\n",
       "      <td>F-C</td>\n",
       "      <td>73.0</td>\n",
       "      <td>239</td>\n",
       "      <td>Texas A&amp;M</td>\n",
       "      <td>Jefferson College (JC)</td>\n",
       "      <td>1989-02-19</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adamsjo01w</td>\n",
       "      <td>C</td>\n",
       "      <td>75.0</td>\n",
       "      <td>180</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981-05-24</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aguilel01w</td>\n",
       "      <td>G</td>\n",
       "      <td>67.0</td>\n",
       "      <td>165</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-10-15</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ajavoma01w</td>\n",
       "      <td>G</td>\n",
       "      <td>68.0</td>\n",
       "      <td>160</td>\n",
       "      <td>Rutgers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986-05-07</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>alberma01w</td>\n",
       "      <td>G</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-04-12</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aldrima01w</td>\n",
       "      <td>G</td>\n",
       "      <td>71.0</td>\n",
       "      <td>153</td>\n",
       "      <td>UNC Charlotte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973-09-15</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>alexaer01w</td>\n",
       "      <td>G</td>\n",
       "      <td>67.0</td>\n",
       "      <td>140</td>\n",
       "      <td>California-Santa Barbara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-04-25</td>\n",
       "      <td>0000-00-00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bioID  pos  height  weight                   college   \n",
       "0   abrahta01w    C    74.0     190         George Washington  \\\n",
       "1   abrossv01w    F    74.0     169               Connecticut   \n",
       "2   adairje01w    C    76.0     197         George Washington   \n",
       "3   adamsda01w  F-C    73.0     239                 Texas A&M   \n",
       "4   adamsjo01w    C    75.0     180                New Mexico   \n",
       "8   aguilel01w    G    67.0     165         George Washington   \n",
       "9   ajavoma01w    G    68.0     160                   Rutgers   \n",
       "10  alberma01w    G    64.0       0                Ohio State   \n",
       "11  aldrima01w    G    71.0     153             UNC Charlotte   \n",
       "12  alexaer01w    G    67.0     140  California-Santa Barbara   \n",
       "\n",
       "              collegeOther   birthDate   deathDate  \n",
       "0                      NaN  1975-09-27  0000-00-00  \n",
       "1                      NaN  1980-07-09  0000-00-00  \n",
       "2                      NaN  1986-12-19  0000-00-00  \n",
       "3   Jefferson College (JC)  1989-02-19  0000-00-00  \n",
       "4                      NaN  1981-05-24  0000-00-00  \n",
       "8                      NaN  1976-10-15  0000-00-00  \n",
       "9                      NaN  1986-05-07  0000-00-00  \n",
       "10                     NaN  1975-04-12  0000-00-00  \n",
       "11                     NaN  1973-09-15  0000-00-00  \n",
       "12                     NaN  1975-04-25  0000-00-00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_players = df_players[~((df_players['pos'].isna()) &\n",
    "                            (df_players['height'] == 0.0) &\n",
    "                            (df_players['weight'] == 0) &\n",
    "                            (df_players['college'].isna()) &\n",
    "                            (df_players['collegeOther'].isna()) &\n",
    "                            (df_players['birthDate'] == \"0000-00-00\") &\n",
    "                            (df_players['deathDate'] == \"0000-00-00\"))]\n",
    "df_players.to_csv('data/players_processed.csv', index=False)\n",
    "df_players.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "award_counts = df_awards_players.groupby([\"year\", \"playerID\"]).size().reset_index(name=\"award_count\")\n",
    "award_counts_copy = award_counts.copy()\n",
    "sum_collumns = ['award_count']\n",
    "\n",
    "for year in years:\n",
    "    players = award_counts[(award_counts['year'] == year)]['playerID'].unique()\n",
    "    for player in players:\n",
    "        for column in sum_collumns:\n",
    "            award_counts_copy.loc[(award_counts_copy['year'] == year) & (award_counts_copy['playerID'] == player), column] = award_counts[(award_counts['year'] >= (year - years_back)) &(award_counts['year'] < year) & (award_counts['playerID'] == player)][column].sum()\n",
    "\n",
    "award_counts_copy.fillna(0, inplace=True)\n",
    "award_counts_copy.to_csv('data/awards_players_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
